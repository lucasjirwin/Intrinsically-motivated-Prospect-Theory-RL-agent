# Meta-Learning-aspiration-RL-agent

Senior Thesis Project at Princeton. I am currently working on developing a reinforcement learning agent with an adjusted reward function such that $r = w_1 \cdot r_t + (r - \rho)$ where $\rho$ is the "aspiration" of the agent â€“ the reward the agent expects to achieve to be minimally satisfied. 
